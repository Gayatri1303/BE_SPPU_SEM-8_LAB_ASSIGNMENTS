{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "76v0GIA_CajP"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Flatten, Dropout, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zg9MHJNUD84a",
    "outputId": "08ec29af-2991-462a-8274-8db3a1234652"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\gayat\\Downloads\\imdb\\IMDB Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "ueyNFL-CEDY4",
    "outputId": "74916417-b652-4c4a-defe-52c084842729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "3ijZLsjOEJMf",
    "outputId": "79d019c6-d6c7-4c20-8048-5bf4c94b1c91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label Encoding: Convert 'positive' to 1 and 'negative' to 0\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z_y8J5OAEOPJ"
   },
   "outputs": [],
   "source": [
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Text Preprocessing: Tokenization & Padding\n",
    "vocab_size = 10000  # Number of unique words to keep\n",
    "max_length = 200  # Max review length\n",
    "oov_token = \"<OOV>\"  # Out of vocabulary token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTyYxNaRESD7",
    "outputId": "beec4f02-c8a8-49dc-ca08-e6c7c1cf0fbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 215ms/step - accuracy: 0.5161 - loss: 0.6919 - val_accuracy: 0.5039 - val_loss: 0.6931\n",
      "Epoch 2/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1079s\u001b[0m 863ms/step - accuracy: 0.5029 - loss: 0.6934 - val_accuracy: 0.5093 - val_loss: 0.6929\n",
      "Epoch 3/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 216ms/step - accuracy: 0.5745 - loss: 0.6653 - val_accuracy: 0.6270 - val_loss: 0.6383\n",
      "Epoch 4/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 205ms/step - accuracy: 0.6266 - loss: 0.6469 - val_accuracy: 0.7603 - val_loss: 0.5167\n",
      "Epoch 5/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 210ms/step - accuracy: 0.8313 - loss: 0.4066 - val_accuracy: 0.8510 - val_loss: 0.3601\n",
      "Epoch 6/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41113s\u001b[0m 33s/step - accuracy: 0.8977 - loss: 0.2719 - val_accuracy: 0.8810 - val_loss: 0.2880\n",
      "Epoch 7/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 102ms/step - accuracy: 0.9287 - loss: 0.2015 - val_accuracy: 0.8781 - val_loss: 0.3009\n",
      "Epoch 8/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 80ms/step - accuracy: 0.9533 - loss: 0.1468 - val_accuracy: 0.8708 - val_loss: 0.3472\n",
      "Epoch 9/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 81ms/step - accuracy: 0.9702 - loss: 0.1038 - val_accuracy: 0.8702 - val_loss: 0.3899\n",
      "Epoch 10/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 73ms/step - accuracy: 0.9806 - loss: 0.0714 - val_accuracy: 0.8632 - val_loss: 0.4374\n",
      "Epoch 11/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 83ms/step - accuracy: 0.9883 - loss: 0.0489 - val_accuracy: 0.8634 - val_loss: 0.4487\n",
      "Epoch 12/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 85ms/step - accuracy: 0.9909 - loss: 0.0408 - val_accuracy: 0.8635 - val_loss: 0.5652\n",
      "Epoch 13/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 105ms/step - accuracy: 0.9927 - loss: 0.0323 - val_accuracy: 0.8650 - val_loss: 0.5952\n",
      "Epoch 14/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 103ms/step - accuracy: 0.9941 - loss: 0.0262 - val_accuracy: 0.8623 - val_loss: 0.6300\n",
      "Epoch 15/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 94ms/step - accuracy: 0.9959 - loss: 0.0214 - val_accuracy: 0.8619 - val_loss: 0.6053\n",
      "Epoch 16/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 88ms/step - accuracy: 0.9958 - loss: 0.0185 - val_accuracy: 0.8623 - val_loss: 0.5728\n",
      "Epoch 17/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 117ms/step - accuracy: 0.9955 - loss: 0.0179 - val_accuracy: 0.8599 - val_loss: 0.6774\n",
      "Epoch 18/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 206ms/step - accuracy: 0.9971 - loss: 0.0131 - val_accuracy: 0.8583 - val_loss: 0.7716\n",
      "Epoch 19/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 183ms/step - accuracy: 0.9976 - loss: 0.0109 - val_accuracy: 0.8551 - val_loss: 0.8250\n",
      "Epoch 20/20\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2624s\u001b[0m 2s/step - accuracy: 0.9962 - loss: 0.0145 - val_accuracy: 0.8576 - val_loss: 0.7850\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 52ms/step\n"
     ]
    }
   ],
   "source": [
    "# Initialize Tokenizer\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post', truncating='post')\n",
    "\n",
    "# Build the Deep Neural Network Model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, 128, input_length=max_length),  # Embedding layer\n",
    "    LSTM(64, return_sequences=True),  # LSTM layer for sequential data\n",
    "    LSTM(32),  # Another LSTM layer\n",
    "    Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    Dense(32, activation='relu'),  # Dense hidden layer\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(X_train_pad, y_train, epochs=20, batch_size=32, validation_data=(X_test_pad, y_test))\n",
    "\n",
    "# Evaluate the Model\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)  # Convert probabilities to binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "FvBwZGO1EtX1",
    "outputId": "7beedab9-c58c-4b12-a969-e866c28a808e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8576\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      4961\n",
      "           1       0.86      0.86      0.86      5039\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n",
      "Number of Misclassified Samples: 1424\n",
      "\n",
      "Some Misclassified Reviews:\n",
      "\n",
      "Review: I really liked this Summerslam due to the look of the arena, the curtains and just the look overall was interesting to me for some reason. Anyways, this could have been one of the best Summerslam's ever if the WWF didn't have Lex Luger in the main event against Yokozuna, now for it's time it was ok to have a huge fat man vs a strong man but I'm glad times have changed. It was a terrible main event just like every match Luger is in is terrible. Other matches on the card were Razor Ramon vs Ted Dibiase, Steiner Brothers vs Heavenly Bodies, Shawn Michaels vs Curt Hening, this was the event where Shawn named his big monster of a body guard Diesel, IRS vs 1-2-3 Kid, Bret Hart first takes on Doink then takes on Jerry Lawler and stuff with the Harts and Lawler was always very interesting, then Ludvig Borga destroyed Marty Jannetty, Undertaker took on Giant Gonzalez in another terrible match, The Smoking Gunns and Tatanka took on Bam Bam Bigelow and the Headshrinkers, and Yokozuna defended the world title against Lex Luger this match was boring and it has a terrible ending. However it deserves 8/10\n",
      "True Sentiment: Positive\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: I was very disappointed with this series. It had lots of cool graphics and that's about it. The level of detail it went into was minimal, and I always got the feeling the audience was being patronized -- there was a lot of what seemed to me as \"This is extremely cool but we're not going to explain it in further detail because you won't get it anyway. Let's just show you some pretty pictures to entertain you.\" The host would drop interesting-sounding words such as \"sparticles\" and \"super-symmetry\" without any attempt at explaining what it was. We had to look it up on Wikipedia.<br /><br />Furthermore, I know quite a bit about superstrings (for a layman) and I found their explanations were convoluted and could have been so much better. They could have chosen MUCH better examples to explain concepts, but instead, the examples they used were confusing and further obscured the subject.<br /><br />Additionally, I got so sick of the repetitiveness. They could easily have condensed the series into one episode if they had cut out all the repetition. They must have shown the clips of the Quantum Café about 8 times. The host kept saying the same things over and over and over again. I can't remember how many times he said \"The universe is made out of tiny little vibrating strings.\" It's like they were trying to brainwash us into just accepting \"superstrings are the best thing since sliced bread.\"<br /><br />Finally, the show ended off with an unpleasant sense of a \"competition\" between Fermilab and CERN, clearly biased towards Fermilab. This is supposed to be an educational program about quantum physics, not about whether the US is better than Europe or vice versa! I also felt that was part of the patronizing -- \"Audiences need to see some conflict to remain interested.\" Please. Give me a little more credit than that.<br /><br />Overall, 2 thumbs down :-(\n",
      "True Sentiment: Negative\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: I went to see Hamlet because I was in between jobs. I figured 4 hours would be great, I've been a fan of Branagh; Dead Again, Henry V. I was completely overwhelmed by the direction, acting, cinematography that this film captured. Like other reviews the 4 hours passes swiftly. Branagh doesn't play Hamlet, he is Hamlet, he was born for this. When I watch this film I'm constantly trying to find faults, I've looked at the goofs and haven't noticed them. How he was able to move the camera in and out of the Hall with all the mirrors is a mystery to me. This movie was shot in 70 mil. It's a shame that Columbia hasn't released a Widescreen version of this on VHS. I own a DVD player, and I'd take this over Titanic any day. So Columbia if you're listening put this film out the way it should be watched! And I don't know what happened at the Oscars. This should have swept Best Picture, Best Actor, Best Direction, best cinematography. What films were they watching? I felt sorry for Branagh at the Oscars when he did a tribute to Shakespeare on the screen. They should have been giving a tribute to Branagh for bringing us one of the greatest films of all time.\n",
      "True Sentiment: Positive\n",
      "Predicted Sentiment: Negative\n",
      "\n",
      "Review: I'm writing this note as a chess player as well as as a movie viewer. I watched the 1997 Kasparov-Deep Blue games on the Internet. I know something about the issues that were raised. Other chess players will come along and want to know whether this movie is worth seeing/buying, and I'm talking largely to them. However, I'll try not to ignore those who aren't \"into chess\".<br /><br />This movie is about the 1997 match between Garry Kasparov and the custom-built computer \"Deep Blue\". However, the first image you see in the movie is not of Kasparov, or of the computer, but of \"THE TURK\". This is an \"automaton\" which was built in Europe at the turn of the 18th-19th century and played winning chess against all comers. I put the word \"automaton\" in quotes because it was, as everyone now knows, a fake. There was a man inside it.<br /><br />If you don't like seeing \"THE TURK\", then you won't be able to stand the movie, because \"THE TURK\" has as much screen time as Kasparov, maybe more, both in modern footage and in b/w footage from some old movie. The reappearance of \"THE TURK\" every few seconds underscores Kasparov's charge that \"Deep Blue\" had human assistance - that it was (to some degree) a fake computer, that IBM cheated, that there was \"a man inside it\" working behind the scenes to help it win. Not only does Kasparov believe this, but the filmmakers seem to believe it too. And so this is not really much of a movie about chess games or about programming chess computers. It is a propaganda piece about a big corporation supposedly misusing a helpless grandmaster. Really it is a lot like a \"negative campaign ad\", as it is chock full of ominous music and evocative camera work and spooky sound effects and innuendos (\"we never found out what was behind that locked door\") and the ever-present \"TURK\".<br /><br />Now, most people in the chess community are pretty much convinced that IBM did not cheat and that this was Garry's paranoia at work. To start with, in order for a human to help \"Deep Blue\" beat Kasparov, it would seem that you would need a human who was better than \"Deep Blue\" AND better than Kasparov. Since there was no such person, the whole idea is a bit suspect from the start. Furthermore, by the time this movie was made, there were computer programs that could run on your PC that could beat strong grandmasters. Today, much more than in 1997, we take it for granted that a computer can do things you might not expect. And we are less likely to take it as a monumental human tragedy that a computer beat a guy in chess. (And in fact, the bottom line is that Kasparov beat himself with two bad mistakes, including resigning game 2 in a drawn position.) <br /><br />As for the chess games, you actually see very little of them. There are a few comments from masters and commentators that tell briefly how they went, but really you don't get to see hardly any of the strategy or tactics at all. Naturally as a chess player I take this as a major shortcoming, but I think that non-players are being cheated too. Imagine a baseball movie, for example, where you don't hardly get to see any of the game - just a commentator telling you that \"in Game Four, the White Sox defeated the Astros with such and such a score.\" Nobody would make a movie like that. But here, for example, we are told that Kasparov made a bad blunder in the opening of the decisive game 6, but we aren't shown the position on the screen, or told why it was a blunder, or what he should have done instead, or anything. We just see a few seconds of Kasparov holding his head in his hands, and then more atmospheric sound effects and camera work.<br /><br />(Since I saw this on DVD, let me warn chess players about the DVD as well. The jacket promises you that the Extras include the games \"with analysis\". Is this grandmaster analysis, which people like us might find interesting? NO! It is the automated computer voice synthesizer analysis from some version of Chessmaster, that tells you when a piece is attacked and a pawn gets isolated and that you are in the \"Caro-Kann Defense, Main Line\". Blahhhh.) <br /><br />Someone might then come along and say, \"Well, clearly this movie is meant to dramatize the match for the non-player, and so it's unfair to be impatient with it.\" But actually it doesn't do a very good job of reaching out to the non-player either - it skates over some points that a true novice would really want to have explained. For example it says that Kasparov could have gotten \"perpetual check\" in the second game, but it doesn't explain what that is (or show what it would have looked like on the board, which would have been interesting). It flashes back to the Kasparov-Karpov matches but doesn't explain why there were two of them or who organized them etc. I didn't need this information myself, but I'm familiar with it. If you don't already have chess experience, there are places where you are going to be confused, and this is just a defect in the film.<br /><br />Ultimately I can't recommend the movie, which, like \"THE TURK\" itself, is not what it purports to be (a documentary) but more of a stage illusion.\n",
      "True Sentiment: Negative\n",
      "Predicted Sentiment: Positive\n",
      "\n",
      "Review: Eyeliner was worn nearly 6000 years ago in Egypt. Really not that much of a stretch for it to be around in the 12th century. I also didn't realize the series flopped. There is a second season airing now isn't there? It is amazing to me when commentaries are made by those who are either ill-informed or don't watch a show at all. It is a waste of space on the boards and of other's time. The first show of the series was maybe a bit painful as the cast began to fall into place, but that is to be expected from any show. The remainder of the first season is excellent. I can hardly wait for the second season to begin in the United States.\n",
      "True Sentiment: Positive\n",
      "Predicted Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Analyze Misclassifications\n",
    "misclassified_idx = np.where(y_pred.flatten() != y_test.values)[0]\n",
    "print(f\"Number of Misclassified Samples: {len(misclassified_idx)}\")\n",
    "print(\"\\nSome Misclassified Reviews:\")\n",
    "for i in misclassified_idx[:5]:  # Show 5 misclassified reviews\n",
    "    print(\"\\nReview:\", X_test.iloc[i])\n",
    "    print(\"True Sentiment:\", \"Positive\" if y_test.iloc[i] == 1 else \"Negative\")\n",
    "    print(\"Predicted Sentiment:\", \"Positive\" if y_pred[i] == 1 else \"Negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E77yEO3lxfDb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
