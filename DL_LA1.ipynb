{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c27e1748-78e8-4340-877a-37410b8c5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7663e6bb-b198-4cec-baea-d5c6d20c54e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\gayat\\Downloads\\archive\\HousingData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5827b93-814b-4578-8af4-5747bb4286f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "478ae13e-7f88-42c3-be39-6d6b1a5b689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM       0\n",
      "ZN         0\n",
      "INDUS      0\n",
      "CHAS       0\n",
      "NOX        0\n",
      "RM         0\n",
      "AGE        0\n",
      "DIS        0\n",
      "RAD        0\n",
      "TAX        0\n",
      "PTRATIO    0\n",
      "B          0\n",
      "LSTAT      0\n",
      "MEDV       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CRIM'].fillna(df['CRIM'].mean(), inplace=True)\n",
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['INDUS'].fillna(df['INDUS'].mean(), inplace=True)\n",
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ZN'].fillna(df['ZN'].mean(), inplace=True)\n",
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['CHAS'].fillna(df['CHAS'].mean(), inplace=True)\n",
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['AGE'].fillna(df['AGE'].mean(), inplace=True)\n",
      "C:\\Users\\gayat\\AppData\\Local\\Temp\\ipykernel_5600\\1009835634.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['LSTAT'].fillna(df['LSTAT'].mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "MEDV       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill NaN values with the column mean\n",
    "df['CRIM'].fillna(df['CRIM'].mean(), inplace=True)\n",
    "df['INDUS'].fillna(df['INDUS'].mean(), inplace=True)\n",
    "df['ZN'].fillna(df['ZN'].mean(), inplace=True)\n",
    "df['CHAS'].fillna(df['CHAS'].mean(), inplace=True)\n",
    "df['AGE'].fillna(df['AGE'].mean(), inplace=True)\n",
    "df['LSTAT'].fillna(df['LSTAT'].mean(), inplace=True)\n",
    "\n",
    "# Verify the DataFrame\n",
    "print(df.isna().sum())\n",
    "\n",
    "\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b899a426-b8eb-4829-9ffa-eba490aa14b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7084"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcae896d-3af6-4928-97b0-8ea67180cd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='MEDV'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "sns.boxplot(df['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff5a866c-5cea-4cde-a189-45e183744688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, target_column):\n",
    "    Q1 = df[target_column].quantile(0.25)  # 25th percentile\n",
    "    Q3 = df[target_column].quantile(0.75)  # 75th percentile\n",
    "    IQR = Q3 - Q1  # Interquartile range\n",
    "\n",
    "# Define lower and upper bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "    df = df[(df[target_column] >= lower_bound) & (df[target_column] <= upper_bound)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "768fe6e0-ee35-4de0-a7e8-04571143867c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='MEDV'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGKCAYAAAAWvavcAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGl9JREFUeJzt3QmMVtXd+PHfIDCgMkMBZaAMFNw3bGsMEpc/dUOIRCpJXdoC1UpdE6FGS8UFLS/WpC6NCFVR9H1FEi1otBVSsUBsxYopwSWhQBEwLLa2MICyFObNvf93JowFdajMfc7M55PcPDzLDKdVnC/nnntuWW1tbW0AACSoVdEDAADYX0IGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZLWOZm737t2xdu3a6NChQ5SVlRU9HADgC8j26928eXN07949WrVq1XJDJouY6urqoocBAOyHNWvWRI8ePVpuyGQzMXX/R1RUVBQ9HADgC6ipqcknIup+jrfYkKk7nZRFjJABgLR83rIQi30BgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJLV7DfEA5qnXbt2xZIlS+If//hHdOrUKfr27RsHHXRQ0cMCmpiQAZKzYMGCePjhh2P9+vX1r1VVVcW1114bZ511VqFjA5qWU0tAchFzxx13xD//+c8Gr2fPs9ez94GWQ8gASZ1Ouu+++6K2tja++c1vxqRJk+K3v/1t/pg9z16///77888BLYOQAZKxePHi2LhxY5x00kn57Mt7770Xjz76aP6YPc9ez2Zmss8BLYM1MkAy6gKlc+fOMXjw4Ni9e3f9e5MnT65fH5N97pRTTilsnEDTMSMDJGfevHmNeh1ovoQMkIwTTzyx/tetWzecUN7z+Z6fA5o3IQMk469//Wv9rw8++OD48Y9/HM8991z+mD3f2+eA5s0aGSAZ77zzTv2vP/nkk/jFL35R/7y8vHyvnwOaNzMyQDK2b9+eP/bv3z86duzY4L2vfOUrcdpppzX4HND8mZEBknH00UfHokWL4u23345f//rX+WXXdbcoOP7442PYsGH1nwNaBjMyQDLqLqnesmVLXHLJJfHBBx/EySefnD9mz7PX9/wc0PyZkQGS8fWvfz0/pZRtipcde66RqZO9n30OaBnMyADJyO5uPWbMmH9b3Lvn8+x9d8GGlkPIAEnJdu+966679rrYN3vd3a+hZSmrze6y1ozV1NREZWVlbNq0KSoqKooeDs3Atm3bYvXq1UUPo8XLbk+wbNmy/M929mf8qKOOilat/N2saD179ox27doVPQxa0M9va2SgkbKIGTVqVNHDgJL0yCOPuGqMJlVoyGQ3ecuO999/P39+wgknxO233x6DBg3Knw8YMCDmz5/f4Gt+9KMfxZQpUwoZL9T9jTP7jzXFW7VqVUyYMCFuvfXW6NWrV9HD4f/+fECLCZkePXrEPffck08JZ2e4nnzyybjoooviz3/+cx41mauuuio/711nz23IoQjZtLm/cZaWLGL8M4GWqdCQGTJkSIPn2d+sshmahQsX1odMFi5VVVUFjRAAKGUlszJu165dMWPGjNi6dWu+/Xidp59+Orp06ZLfzXbs2LHx8ccff+b3ybYmzxYI7XkAAM1T4Yt9s63Gs3DJrgQ59NBDY9asWflW45nLL788nzLu3r17LFmyJG655ZZYunRpzJw5c5/fb+LEiTF+/Pgm/F8AALTYy6937NiRXwWSXV713HPPxWOPPZYv8K2LmT29+uqrcc4558Ty5cvjiCOO2OeMzJ43jMtmZKqrq11+Dc3QX/7yl/wKMlfKQPOTzOXXbdu2jSOPPLL+/ihvvvlmPPjgg/GrX/3q3z7br1+//PGzQibb3fPTO34CAM1TyayR2XOTqz1nVPa0ePHi/LFbt25NPCoAoBQVOiOTLd7N9ozJ9h3YvHlzTJ8+PebNmxdz5syJFStW5M8HDx4cnTt3ztfIjB49Ot9+vG/fvkUOGwAoEYWGzIcffhjDhw+PdevW5efBskDJIua8886LNWvWxCuvvBIPPPBAfiVTts5l2LBhMW7cuCKHDACUkEJDZurUqft8LwuXT+/qCwBQ0mtkAAC+KCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkqNGQmT54cffv2jYqKivzo379/vPzyy/Xvb9u2La677rro3LlzHHrooTFs2LDYsGFDkUMGAEpIoSHTo0ePuOeee+Ktt96KRYsWxdlnnx0XXXRRvPvuu/n7o0ePjhdffDGeffbZmD9/fqxduzYuvvjiIocMAJSQ1kX+5kOGDGnwfMKECfkszcKFC/PImTp1akyfPj0PnMwTTzwRxx13XP7+aaedVtCoAYBSUTJrZHbt2hUzZsyIrVu35qeYslmanTt3xrnnnlv/mWOPPTZ69uwZr7/++j6/z/bt26OmpqbBAQA0T4WHzNtvv52vfykvL4+rr746Zs2aFccff3ysX78+2rZtGx07dmzw+a5du+bv7cvEiROjsrKy/qiurm6C/xUAQIsMmWOOOSYWL14cb7zxRlxzzTUxYsSIeO+99/b7+40dOzY2bdpUf6xZs+ZLHS8AUDoKXSOTyWZdjjzyyPzXp5xySrz55pvx4IMPxiWXXBI7duyIjRs3NpiVya5aqqqq2uf3y2Z2sgMAaP4Kn5H5tN27d+frXLKoadOmTcydO7f+vaVLl8bq1avzNTQAAIXOyGSngQYNGpQv4N28eXN+hdK8efNizpw5+fqWK6+8MsaMGROdOnXK95m54YYb8ohxxRIAUHjIfPjhhzF8+PBYt25dHi7Z5nhZxJx33nn5+/fff3+0atUq3wgvm6UZOHBgPPzww/7JAQDFh0y2T8xnadeuXUyaNCk/AABKfo0MAMAXJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFmFhszEiRPj1FNPjQ4dOsThhx8eQ4cOjaVLlzb4zIABA6KsrKzBcfXVVxc2ZgCgdBQaMvPnz4/rrrsuFi5cGL/73e9i586dcf7558fWrVsbfO6qq66KdevW1R/33ntvYWMGAEpH6yJ/89mzZzd4Pm3atHxm5q233oqzzjqr/vWDDz44qqqqChghAFDKSmqNzKZNm/LHTp06NXj96aefji5dusSJJ54YY8eOjY8//nif32P79u1RU1PT4AAAmqdCZ2T2tHv37rjxxhvj9NNPz4OlzuWXXx69evWK7t27x5IlS+KWW27J19HMnDlzn+tuxo8f34QjBwCipYdMtlbmnXfeiddee63B66NGjar/9UknnRTdunWLc845J1asWBFHHHHEv32fbMZmzJgx9c+zGZnq6uoDPHoAoMWGzPXXXx8vvfRSLFiwIHr06PGZn+3Xr1/+uHz58r2GTHl5eX4AAM1foSFTW1sbN9xwQ8yaNSvmzZsXvXv3/tyvWbx4cf6YzcwAAC1b66JPJ02fPj1eeOGFfC+Z9evX569XVlZG+/bt89NH2fuDBw+Ozp0752tkRo8enV/R1Ldv3yKHDgC09JCZPHly/aZ3e3riiSdi5MiR0bZt23jllVfigQceyPeWyda6DBs2LMaNG1fQiAGAUlL4qaXPkoVLtmkeAEDJ7yMDANAYQgYASFZJXH7NF7Nhw4b63Y+BiFWrVjV4BKL+opmuXbtGS1BW+3kLVRKXbYiX/QPNAqCioiJSjpjvfX947NyxveihAFDi2rQtj//576eSjpkv+vPbjEwisn+QWcR80uf/xe52lUUPB4AS1Wrbpoi/zs9/bqQcMl+UkElMFjG7D+lS9DAAoCRY7AsAJEvIAADJEjIAQLKEDACQLCEDACRLyAAAyRIyAECyhAwAkCwhAwAkS8gAAMkSMgBAsoQMAJAsIQMAtIyQeeihh2Ljxo0HbjQAAAcqZG699dbo3r17XH755fHqq6825ksBAIoNmfXr18eUKVNi3bp1cd5550Xv3r3j7rvvjjVr1nz5IwMA+DJDpn379jF8+PD4/e9/H8uWLYvvf//7MXXq1DxoLrjggnj22Wdj586djfmWAABNv9i3T58+cdddd8XKlSvj5Zdfjs6dO8fIkSPjq1/96v6PBgCgKa9aKisri9atW+ePtbW1ZmQAgNIPmWxdTDYjk83MZOtl1q5dG48++mi+fgYAoCm0bsyHd+zYETNnzozHH388v2qpW7duMWLEiLjiiivyoAEAKNmQqaqqio8//jguvPDCePHFF2PgwIHRqpU99QCABEJm3Lhx+ZVKhx122IEbEQDAgQiZMWPG5I/ZpdcvvPBCvP/++/ki3+zy66FDhzq9BACUbshkJk6cGLfddlt+hdLhhx+eP/7tb3+Ln/zkJ/Ff//VfcdNNNx2YkQIAfEqjFrhkG+Flp5ey4+9//3t+hVK2229dyGTHggULGvMtAQCaZkYmuz3BD3/4w7jzzjsbvN6pU6f8UuwsaiZPnhxnnXXW/o8IAOBAzMj86U9/yhf77kv23sKFCxvzLQEAmiZkNmzYEF/72tf2+X626DeblQEAKLmQ2bZtW7Rt23af77dp0ybfNA8AoCSvWnrsscfi0EMP3et7mzdv/jLGBADw5YdMz5498/spfd5nAABKLmSyDfAAAEqFGyUBAC1jRmbw4MHxzDPPRGVlZf78nnvuiauvvjo6duyYP//oo4/izDPPjPfee+/AjJZo9cnGoocAQAlr1cJ+TjQqZObMmRPbt2+vf57dkuA73/lOfcj861//iqVLl375o6Re+5V2TgaA/QqZ7L5Kn/WcA++T3mfF7vb/PxwBYG8zMi3pL72NvvyaYmURs/uQLkUPAwDSW+xbVlaWH59+bX9ld9I+9dRTo0OHDvmdtIcOHfpvp6ayTfiuu+666Ny5c75/zbBhw/IdhgEAGn1qaeTIkVFeXl4fGdli30MOOSR/vuf6mS9i/vz5eaRkMZOtr/npT38a559/fr5YuO57jh49On7zm9/Es88+my8yvv766+Piiy+OP/zhD436vQCAFh4yw4cPbzAD873vfW+vn/miZs+e3eD5tGnT8pmZt956K7+D9qZNm2Lq1Kkxffr0OPvss/PPPPHEE3HcccflN6c87bTTGjN8AKAlh0wWGgdSFi6ZTp065Y9Z0OzcuTPOPffc+s8ce+yx+e7Br7/++l5DJpsV2nNmqKam5oCOGQBIJGSuuOKKz/1MNmOTzaI01u7du+PGG2+M008/PU488cT8texO2tlNKusu767TtWvXfd5lO1t3M378+Eb//gBAC5iR6dWrV3zjG9/40i+9ztbKvPPOO/Haa6/9R99n7NixMWbMmAYzMtXV1V/CCAGApEPmmmuuyXf2XblyZfzgBz/I18jUnQb6T2QLeF966aVYsGBB9OjRo/71qqqq2LFjR2zcuLHBrEx21VL23t5kC5HrFiMDAM1boy6/njRpUqxbty5uvvnmePHFF/OZjmxn32zH3/2Zocm+JouYWbNmxauvvhq9e/du8P4pp5wSbdq0iblz59a/ll2evXr16ujfv3+jfz8AoIVviJfNdlx22WX5sWrVqvx007XXXptfPv3uu+/me7005nRSdkXSCy+8kO8lU7fuJbvMun379vnjlVdemZ8qymZ+Kioq4oYbbsgjxhVLAMB/tLNvq1at8sW92czKrl27Gv31kydPzh8HDBjQ4PXsEutsv5rM/fffn/8+2UZ42dVIAwcOjIcffvg/GTYA0FJDJouJmTNnxuOPP54vzL3wwgvjoYceigsuuCAPjsb4Iqej2rVrl5/Syg4AgP0OmewU0owZM/K1Mdml2NnC3y5d3PcHAEggZKZMmZJvRtenT5/89gLZsTfZjA0AQEnfogAAoEgldYsCAIDGaNzqXACAEiJkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBktS56ADROq22bih4CACWsVQv7OSFkElFZWRlt2pZH/HV+0UMBoMS1aVue/9xoCYRMIrp27Rr/899PxaZNLau04bOsWrUqJkyYELfeemv06tWr6OFAyaisrMx/brQEQiYh2b+ULeVfTGiMLGKOPvrooocBFMBiXwAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZhYbMggULYsiQIdG9e/coKyuL559/vsH7I0eOzF/f87jgggsKGy8AUFoKDZmtW7fGySefHJMmTdrnZ7JwWbduXf3xzDPPNOkYAYDSVei9lgYNGpQfn6W8vDyqqqqabEwAQDpKfo3MvHnz4vDDD49jjjkmrrnmmvjoo48+8/Pbt2+PmpqaBgcA0DyVdMhkp5WeeuqpmDt3bvz85z+P+fPn5zM4u3bt2ufXTJw4Mb99ed1RXV3dpGMGAFrIqaXPc+mll9b/+qSTToq+ffvGEUcckc/SnHPOOXv9mrFjx8aYMWPqn2czMmIGAJqnkp6R+bQ+ffpEly5dYvny5Z+5pqaioqLBAQA0T0mFzAcffJCvkenWrVvRQwEAWvqppS1btjSYXVm5cmUsXrw4OnXqlB/jx4+PYcOG5VctrVixIm6++eY48sgjY+DAgUUOGwAoEYWGzKJFi+Jb3/pW/fO6tS0jRoyIyZMnx5IlS+LJJ5+MjRs35pvmnX/++XH33Xfnp48AAAoNmQEDBkRtbe0+358zZ06TjgcASEtSa2QAAPYkZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWYWGzIIFC2LIkCHRvXv3KCsri+eff77B+7W1tXH77bdHt27don379nHuuefGsmXLChsvAFBaCg2ZrVu3xsknnxyTJk3a6/v33ntv/PKXv4wpU6bEG2+8EYccckgMHDgwtm3b1uRjBQBKT+sif/NBgwblx95kszEPPPBAjBs3Li666KL8taeeeiq6du2az9xceumlTTxaAKDUlOwamZUrV8b69evz00l1Kisro1+/fvH666/v8+u2b98eNTU1DQ4AoHkq2ZDJIiaTzcDsKXte997eTJw4MQ+euqO6uvqAjxUAKEbJhsz+Gjt2bGzatKn+WLNmTdFDAgBaWshUVVXljxs2bGjweva87r29KS8vj4qKigYHANA8lWzI9O7dOw+WuXPn1r+WrXfJrl7q379/oWMDAEpDoVctbdmyJZYvX95gge/ixYujU6dO0bNnz7jxxhvjZz/7WRx11FF52Nx22235njNDhw4tctgAQIkoNGQWLVoU3/rWt+qfjxkzJn8cMWJETJs2LW6++eZ8r5lRo0bFxo0b44wzzojZs2dHu3btChw1AFAqCg2ZAQMG5PvF7Eu22+9dd92VHwAAyayRAQD4PEIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQCSJWQAgGQJGQAgWUIGAEiWkAEAkiVkAIBktS56AJCabdu2xerVq4seBhGxatWqBo8Ur2fPntGuXbuih0ELImSgkbKIGTVqVNHDYA8TJkwoegj8n0ceeSSOPvrooodBCyJkYD/+xpn9xxrY+58PaEpCBhopmzb3N06A0lDSi33vvPPOKCsra3Ace+yxRQ8LACgRJT8jc8IJJ8Qrr7xS/7x165IfMgDQREq+CrJwqaqqKnoYAEAJKulTS5lly5ZF9+7do0+fPvHd7373cy973b59e9TU1DQ4AIDmqaRDpl+/fjFt2rSYPXt2TJ48OVauXBlnnnlmbN68eZ9fM3HixKisrKw/qqurm3TMAEDTKautra2NRGzcuDF69eoV9913X1x55ZX7nJHJjjrZjEwWM5s2bYqKioomHC0AsL+yn9/ZhMTn/fwu+TUye+rYsWN+2evy5cv3+Zny8vL8AACav5I+tfRpW7ZsiRUrVkS3bt2KHgoAUAJKOmRuuummmD9/frz//vvxxz/+Mb797W/HQQcdFJdddlnRQwMASkBJn1r64IMP8mj56KOP4rDDDoszzjgjFi5cmP8aAKCkQ2bGjBlFDwEAKGElfWoJAOCzCBkAIFklfWrpy1C3TY4dfgEgHXU/tz9vu7tmHzJ1uwDb4RcA0vw5nm2M1yx29t0fu3fvjrVr10aHDh2irKys6OEAX6K6nbvXrFlj525oZrI8ySImu99iq1atWm7IAM3XF93CHGi+LPYFAJIlZACAZAkZIFnZDWLvuOMON4qFFswaGQAgWWZkAIBkCRkAIFlCBgBIlpABAJIlZACAZAkZACBZQgYASJaQAQAiVf8LiWgeC+3YtOkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=remove_outliers_iqr(df, 'MEDV')\n",
    "sns.boxplot(df['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4399dc2-b862-4c1f-b655-b60053885725",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.iloc[:,0:-1]\n",
    "y=df['MEDV']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d48d3786-2fe6-4153-b016-e0b2d2aff5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e858cbb3-a899-4d10-adf3-2d0c70dac6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6c6344c2-ba3c-413e-811e-1c4127a031a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gayat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 162.3506 - mae: 9.5108 - val_loss: 37.4438 - val_mae: 5.2067\n",
      "Epoch 2/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 25.0510 - mae: 4.0369 - val_loss: 12.9253 - val_mae: 2.8210\n",
      "Epoch 3/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 20.3941 - mae: 3.5098 - val_loss: 10.3655 - val_mae: 2.4939\n",
      "Epoch 4/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 10.2953 - mae: 2.5231 - val_loss: 8.9700 - val_mae: 2.3985\n",
      "Epoch 5/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2559 - mae: 2.3155 - val_loss: 8.9480 - val_mae: 2.3191\n",
      "Epoch 6/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 14.1598 - mae: 2.9612 - val_loss: 11.1765 - val_mae: 2.5958\n",
      "Epoch 7/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12.3953 - mae: 2.8253 - val_loss: 16.7571 - val_mae: 3.3467\n",
      "Epoch 8/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 16.2353 - mae: 3.1250 - val_loss: 8.4020 - val_mae: 2.1432\n",
      "Epoch 9/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.9104 - mae: 2.3431 - val_loss: 9.5453 - val_mae: 2.4331\n",
      "Epoch 10/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.8414 - mae: 2.4593 - val_loss: 12.3873 - val_mae: 2.8056\n",
      "Epoch 11/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.9018 - mae: 2.4888 - val_loss: 7.4681 - val_mae: 2.1926\n",
      "Epoch 12/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.8963 - mae: 2.0592 - val_loss: 8.2884 - val_mae: 2.3494\n",
      "Epoch 13/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.2207 - mae: 2.2099 - val_loss: 11.5426 - val_mae: 2.7011\n",
      "Epoch 14/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.8777 - mae: 2.5373 - val_loss: 11.2301 - val_mae: 2.5821\n",
      "Epoch 15/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3854 - mae: 2.3779 - val_loss: 8.8782 - val_mae: 2.2928\n",
      "Epoch 16/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1198 - mae: 2.1993 - val_loss: 6.8260 - val_mae: 2.0523\n",
      "Epoch 17/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.1189 - mae: 2.2631 - val_loss: 8.5607 - val_mae: 2.2930\n",
      "Epoch 18/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11.9488 - mae: 2.6002 - val_loss: 10.0320 - val_mae: 2.4311\n",
      "Epoch 19/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6732 - mae: 2.2825 - val_loss: 7.4183 - val_mae: 2.1028\n",
      "Epoch 20/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.5288 - mae: 2.1443 - val_loss: 8.2151 - val_mae: 2.2195\n",
      "Epoch 21/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.0662 - mae: 2.2102 - val_loss: 6.9429 - val_mae: 2.0175\n",
      "Epoch 22/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.1395 - mae: 2.2701 - val_loss: 7.1001 - val_mae: 2.0261\n",
      "Epoch 23/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3911 - mae: 2.0783 - val_loss: 12.2580 - val_mae: 2.7937\n",
      "Epoch 24/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.2005 - mae: 2.3242 - val_loss: 10.0594 - val_mae: 2.4039\n",
      "Epoch 25/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 9.9253 - mae: 2.4218 - val_loss: 9.1502 - val_mae: 2.4626\n",
      "Epoch 26/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10.7665 - mae: 2.7049 - val_loss: 12.0591 - val_mae: 2.6518\n",
      "Epoch 27/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.5111 - mae: 2.4872 - val_loss: 13.5728 - val_mae: 2.9956\n",
      "Epoch 28/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 10.3534 - mae: 2.3880 - val_loss: 7.2320 - val_mae: 2.0747\n",
      "Epoch 29/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9727 - mae: 2.0121 - val_loss: 6.1635 - val_mae: 1.9165\n",
      "Epoch 30/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.4258 - mae: 2.0970 - val_loss: 7.5404 - val_mae: 2.1099\n",
      "Epoch 31/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4278 - mae: 1.9876 - val_loss: 11.0965 - val_mae: 2.7019\n",
      "Epoch 32/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3520 - mae: 2.1433 - val_loss: 7.5583 - val_mae: 2.1228\n",
      "Epoch 33/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.5727 - mae: 2.1797 - val_loss: 7.7235 - val_mae: 2.1369\n",
      "Epoch 34/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3746 - mae: 1.9625 - val_loss: 6.1245 - val_mae: 1.9536\n",
      "Epoch 35/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.2004 - mae: 1.8908 - val_loss: 6.7762 - val_mae: 1.9962\n",
      "Epoch 36/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3311 - mae: 1.7309 - val_loss: 6.8860 - val_mae: 2.0869\n",
      "Epoch 37/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1618 - mae: 2.0383 - val_loss: 6.4711 - val_mae: 1.9206\n",
      "Epoch 38/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8063 - mae: 1.8379 - val_loss: 6.2905 - val_mae: 1.9313\n",
      "Epoch 39/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1002 - mae: 1.8199 - val_loss: 6.4024 - val_mae: 1.9623\n",
      "Epoch 40/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9708 - mae: 1.8269 - val_loss: 5.9653 - val_mae: 1.8153\n",
      "Epoch 41/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6625 - mae: 1.9805 - val_loss: 9.4613 - val_mae: 2.3291\n",
      "Epoch 42/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.9648 - mae: 2.0208 - val_loss: 7.3288 - val_mae: 1.9852\n",
      "Epoch 43/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9834 - mae: 2.1771 - val_loss: 5.6692 - val_mae: 1.8151\n",
      "Epoch 44/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9959 - mae: 1.6980 - val_loss: 6.4927 - val_mae: 1.9364\n",
      "Epoch 45/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0383 - mae: 1.9711 - val_loss: 8.6123 - val_mae: 2.2362\n",
      "Epoch 46/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.5408 - mae: 2.1458 - val_loss: 7.4496 - val_mae: 2.0793\n",
      "Epoch 47/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9320 - mae: 1.8395 - val_loss: 13.9177 - val_mae: 2.8611\n",
      "Epoch 48/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0213 - mae: 2.1804 - val_loss: 11.1924 - val_mae: 2.6203\n",
      "Epoch 49/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.7379 - mae: 2.0119 - val_loss: 10.2597 - val_mae: 2.4929\n",
      "Epoch 50/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.1794 - mae: 2.0629 - val_loss: 6.6815 - val_mae: 1.9304\n",
      "Epoch 51/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6881 - mae: 1.6747 - val_loss: 5.6281 - val_mae: 1.8074\n",
      "Epoch 52/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5216 - mae: 1.8178 - val_loss: 9.3734 - val_mae: 2.3792\n",
      "Epoch 53/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.6859 - mae: 2.0169 - val_loss: 6.6693 - val_mae: 1.9510\n",
      "Epoch 54/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3460 - mae: 1.6049 - val_loss: 7.0604 - val_mae: 2.1290\n",
      "Epoch 55/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1895 - mae: 2.0612 - val_loss: 7.2729 - val_mae: 2.1866\n",
      "Epoch 56/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.1338 - mae: 1.7430 - val_loss: 8.0623 - val_mae: 2.2456\n",
      "Epoch 57/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0401 - mae: 1.8809 - val_loss: 9.1075 - val_mae: 2.5153\n",
      "Epoch 58/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1034 - mae: 1.7573 - val_loss: 6.2100 - val_mae: 1.8862\n",
      "Epoch 59/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4895 - mae: 1.7570 - val_loss: 6.3074 - val_mae: 1.9731\n",
      "Epoch 60/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.2332 - mae: 1.7311 - val_loss: 7.3083 - val_mae: 2.1301\n",
      "Epoch 61/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.7741 - mae: 2.3505 - val_loss: 6.6880 - val_mae: 1.9974\n",
      "Epoch 62/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7667 - mae: 1.8098 - val_loss: 7.5914 - val_mae: 2.1660\n",
      "Epoch 63/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9340 - mae: 1.9095 - val_loss: 8.0109 - val_mae: 2.2479\n",
      "Epoch 64/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1110 - mae: 1.7810 - val_loss: 7.5447 - val_mae: 2.2667\n",
      "Epoch 65/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1787 - mae: 1.9906 - val_loss: 7.1552 - val_mae: 2.0922\n",
      "Epoch 66/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.4871 - mae: 1.7540 - val_loss: 5.7796 - val_mae: 1.9209\n",
      "Epoch 67/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.0118 - mae: 1.8898 - val_loss: 6.0009 - val_mae: 1.9833\n",
      "Epoch 68/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3418 - mae: 1.6293 - val_loss: 6.4607 - val_mae: 1.9430\n",
      "Epoch 69/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.9408 - mae: 1.6977 - val_loss: 6.2023 - val_mae: 1.9672\n",
      "Epoch 70/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8445 - mae: 1.6656 - val_loss: 5.9886 - val_mae: 1.9371\n",
      "Epoch 71/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4650 - mae: 1.6035 - val_loss: 6.3441 - val_mae: 1.9198\n",
      "Epoch 72/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3342 - mae: 1.5461 - val_loss: 6.2985 - val_mae: 2.0141\n",
      "Epoch 73/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2434 - mae: 1.5530 - val_loss: 7.8463 - val_mae: 2.1172\n",
      "Epoch 74/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5840 - mae: 1.7443 - val_loss: 6.4244 - val_mae: 2.0494\n",
      "Epoch 75/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6288 - mae: 1.5767 - val_loss: 6.9993 - val_mae: 2.2100\n",
      "Epoch 76/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.8586 - mae: 1.7153 - val_loss: 8.1872 - val_mae: 2.2946\n",
      "Epoch 77/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9951 - mae: 1.7358 - val_loss: 5.7899 - val_mae: 1.9162\n",
      "Epoch 78/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8528 - mae: 1.6357 - val_loss: 7.5847 - val_mae: 2.1768\n",
      "Epoch 79/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6647 - mae: 1.6639 - val_loss: 6.7327 - val_mae: 2.0666\n",
      "Epoch 80/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.8248 - mae: 1.6428 - val_loss: 5.5300 - val_mae: 1.9792\n",
      "Epoch 81/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.3361 - mae: 1.6022 - val_loss: 6.2092 - val_mae: 1.9212\n",
      "Epoch 82/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.7881 - mae: 1.5698 - val_loss: 6.4658 - val_mae: 1.9746\n",
      "Epoch 83/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.0978 - mae: 1.5608 - val_loss: 6.4938 - val_mae: 1.9808\n",
      "Epoch 84/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3901 - mae: 1.6038 - val_loss: 7.9689 - val_mae: 2.3293\n",
      "Epoch 85/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2539 - mae: 1.7695 - val_loss: 6.1462 - val_mae: 1.9310\n",
      "Epoch 86/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9052 - mae: 1.5108 - val_loss: 6.7271 - val_mae: 2.2191\n",
      "Epoch 87/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.7458 - mae: 1.6171 - val_loss: 5.7249 - val_mae: 1.9815\n",
      "Epoch 88/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.5075 - mae: 1.7973 - val_loss: 10.4767 - val_mae: 2.5108\n",
      "Epoch 89/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.3882 - mae: 1.9487 - val_loss: 10.2577 - val_mae: 2.6013\n",
      "Epoch 90/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0096 - mae: 1.9388 - val_loss: 7.3269 - val_mae: 2.0683\n",
      "Epoch 91/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1696 - mae: 1.7467 - val_loss: 7.8661 - val_mae: 2.1650\n",
      "Epoch 92/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.9697 - mae: 1.5678 - val_loss: 7.1105 - val_mae: 2.1934\n",
      "Epoch 93/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6801 - mae: 1.6448 - val_loss: 11.5984 - val_mae: 2.6459\n",
      "Epoch 94/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.0148 - mae: 1.6999 - val_loss: 6.9484 - val_mae: 2.0744\n",
      "Epoch 95/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.4991 - mae: 1.4779 - val_loss: 7.0960 - val_mae: 2.1166\n",
      "Epoch 96/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6042 - mae: 1.4370 - val_loss: 5.7927 - val_mae: 1.8926\n",
      "Epoch 97/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4710 - mae: 1.5514 - val_loss: 8.4953 - val_mae: 2.2629\n",
      "Epoch 98/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.2289 - mae: 1.7541 - val_loss: 6.5462 - val_mae: 2.0001\n",
      "Epoch 99/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3868 - mae: 1.6914 - val_loss: 5.6496 - val_mae: 1.8788\n",
      "Epoch 100/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1798 - mae: 1.5268 - val_loss: 5.8528 - val_mae: 1.8803\n",
      "Epoch 101/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.2745 - mae: 1.7412 - val_loss: 5.9062 - val_mae: 1.8947\n",
      "Epoch 102/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3954 - mae: 1.5444 - val_loss: 6.1555 - val_mae: 2.0190\n",
      "Epoch 103/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8514 - mae: 1.4416 - val_loss: 7.1502 - val_mae: 2.0559\n",
      "Epoch 104/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3744 - mae: 1.5590 - val_loss: 7.0005 - val_mae: 2.0969\n",
      "Epoch 105/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8958 - mae: 1.5635 - val_loss: 8.2155 - val_mae: 2.3186\n",
      "Epoch 106/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.6038 - mae: 1.8188 - val_loss: 13.3001 - val_mae: 2.8634\n",
      "Epoch 107/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.2564 - mae: 2.0486 - val_loss: 5.8714 - val_mae: 1.9442\n",
      "Epoch 108/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2965 - mae: 1.5933 - val_loss: 9.3727 - val_mae: 2.5176\n",
      "Epoch 109/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.1542 - mae: 1.9387 - val_loss: 6.5567 - val_mae: 1.9461\n",
      "Epoch 110/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8102 - mae: 1.4892 - val_loss: 6.6105 - val_mae: 2.1237\n",
      "Epoch 111/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5653 - mae: 1.4205 - val_loss: 6.1007 - val_mae: 1.9822\n",
      "Epoch 112/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2761 - mae: 1.3646 - val_loss: 6.7114 - val_mae: 2.2122\n",
      "Epoch 113/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.4216 - mae: 1.4034 - val_loss: 6.8190 - val_mae: 2.0273\n",
      "Epoch 114/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.2992 - mae: 1.4025 - val_loss: 5.9288 - val_mae: 1.9935\n",
      "Epoch 115/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.6798 - mae: 1.3975 - val_loss: 6.3259 - val_mae: 2.0223\n",
      "Epoch 116/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0368 - mae: 1.5843 - val_loss: 6.7100 - val_mae: 2.0109\n",
      "Epoch 117/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.7785 - mae: 1.5022 - val_loss: 6.4380 - val_mae: 2.0655\n",
      "Epoch 118/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.2513 - mae: 1.3850 - val_loss: 6.2719 - val_mae: 1.9663\n",
      "Epoch 119/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.3292 - mae: 1.3503 - val_loss: 6.4629 - val_mae: 1.9863\n",
      "Epoch 120/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1698 - mae: 1.2947 - val_loss: 5.8378 - val_mae: 1.9245\n",
      "Epoch 121/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4812 - mae: 1.4689 - val_loss: 6.9812 - val_mae: 2.0571\n",
      "Epoch 122/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.8780 - mae: 1.4680 - val_loss: 6.4094 - val_mae: 1.9301\n",
      "Epoch 123/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1129 - mae: 1.3452 - val_loss: 6.5845 - val_mae: 2.0176\n",
      "Epoch 124/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3.5736 - mae: 1.4360 - val_loss: 7.0366 - val_mae: 2.0938\n",
      "Epoch 125/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.2378 - mae: 1.5050 - val_loss: 7.8718 - val_mae: 2.1234\n",
      "Epoch 126/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2793 - mae: 1.5986 - val_loss: 7.1179 - val_mae: 2.1099\n",
      "Epoch 127/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.7141 - mae: 1.6541 - val_loss: 6.6080 - val_mae: 2.0616\n",
      "Epoch 128/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 3.7908 - mae: 1.4740 - val_loss: 7.1562 - val_mae: 2.1090\n",
      "Epoch 129/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4666 - mae: 1.4319 - val_loss: 6.9839 - val_mae: 2.0978\n",
      "Epoch 130/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 3.1642 - mae: 1.2862 - val_loss: 6.8249 - val_mae: 2.0478\n",
      "Epoch 131/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.4124 - mae: 1.4177 - val_loss: 6.7194 - val_mae: 2.0581\n",
      "Epoch 132/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6188 - mae: 1.2148 - val_loss: 6.4287 - val_mae: 2.0028\n",
      "Epoch 133/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1888 - mae: 1.4031 - val_loss: 6.2469 - val_mae: 2.0456\n",
      "Epoch 134/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.9697 - mae: 1.3030 - val_loss: 7.4639 - val_mae: 2.1939\n",
      "Epoch 135/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4446 - mae: 1.5885 - val_loss: 5.5379 - val_mae: 1.8757\n",
      "Epoch 136/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7229 - mae: 1.4483 - val_loss: 8.1215 - val_mae: 2.2010\n",
      "Epoch 137/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.2030 - mae: 1.3356 - val_loss: 7.8316 - val_mae: 2.1975\n",
      "Epoch 138/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.5775 - mae: 1.3703 - val_loss: 6.9193 - val_mae: 2.0534\n",
      "Epoch 139/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.9548 - mae: 1.3066 - val_loss: 7.4337 - val_mae: 2.1402\n",
      "Epoch 140/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.2445 - mae: 1.5199 - val_loss: 8.8678 - val_mae: 2.4019\n",
      "Epoch 141/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.2337 - mae: 1.4108 - val_loss: 7.5848 - val_mae: 2.2286\n",
      "Epoch 142/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.1520 - mae: 1.3540 - val_loss: 6.3485 - val_mae: 1.9218\n",
      "Epoch 143/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7241 - mae: 1.2510 - val_loss: 9.7536 - val_mae: 2.5055\n",
      "Epoch 144/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9153 - mae: 1.3208 - val_loss: 6.8301 - val_mae: 2.0785\n",
      "Epoch 145/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8053 - mae: 1.2699 - val_loss: 5.3305 - val_mae: 1.8441\n",
      "Epoch 146/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6283 - mae: 1.2722 - val_loss: 6.4458 - val_mae: 1.9958\n",
      "Epoch 147/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6360 - mae: 1.2676 - val_loss: 7.3887 - val_mae: 2.1105\n",
      "Epoch 148/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.2741 - mae: 1.1261 - val_loss: 6.8260 - val_mae: 2.0232\n",
      "Epoch 149/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7658 - mae: 1.2829 - val_loss: 8.1767 - val_mae: 2.2136\n",
      "Epoch 150/150\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3.2964 - mae: 1.3514 - val_loss: 9.6791 - val_mae: 2.4703\n"
     ]
    }
   ],
   "source": [
    "# Define Deep Neural Network Model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.05), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8910c75f-280b-40d1-8ab6-28648be875cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 9.2132 - mae: 2.2340\n",
      "Test Loss: 9.507688522338867, Test MAE: 2.3241770267486572\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "R-squared: 0.7629919320454428\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss}, Test MAE: {test_mae}\")\n",
    "\n",
    "\n",
    "# Calculate R-squared (which can be interpreted as a measure of \"goodness of fit\")\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892a1c3-1844-4919-a53f-ed5fbe327721",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
